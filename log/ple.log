nohup: 忽略输入
2025-01-04 16:01:22.221208: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-01-04 16:01:22.272535: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-01-04 16:01:23.091472: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Namespace(add_num_times=2, alpha=0.4, anneal_cap=0.2, bert_mask_prob=0.3, best_metric='NDCG@10', block_num=2, cand_num=100, ch=True, context_window=2, dataset_path='data/Tenrec/test_ctr.csv', decay_step=5, device='cpu', dilations=[1, 4], dropout=0.3, early_stop=True, embedding_size=32, epochs=100, eval=True, factor_num=128, gamma=0.5, hidden_size=128, hidden_size_list=[128, 128], init_method='default', is_mp=False, is_parallel=False, is_pretrain=1, item_min=10, k=20, kd=False, kernel_size=3, l2_emb=0.0, latent_dim=128, lifelong_eval=True, ll_max_itemnum=0, local_rank=None, loss_type='BPR', lr=0.0001, max_len=20, mess_dropout=0.1, metric_ks=[5, 20], model_name='ple', mtl_task_num=2, negsample_savefolder='./data/neg_data/', negsample_size=99, node_dropout=0.1, num_embedding=1, num_gpu=1, num_groups=4, num_heads=4, num_items=1, num_labels=1, num_ng=4, num_users=1, optimizer='default', pad_token=0, pretrain_path='', prun_rate=0, re_epochs=20, reg_1=0.0, reg_2=0.0, rho=0.5, sample='random', sample_method='high-pop', sample_ratio=0.3, save_path='./checkpoint/', seed=100, source_path='', target_path='', task=-1, task1_out=0, task2_out=0, task3_out=0, task4_out=0, task_name='mtl', task_num=4, temp=7, test_batch_size=4096, test_method='ufo', test_size=0.1, total_anneal_steps=1000, train_batch_size=4096, user_profile='gender', val_batch_size=4096, val_method='ufo', val_size=0.1111, valid_rate=100, weight_decay=0.0)
  0%|          | 0/15 [00:00<?, ?it/s]  7%|▋         | 1/15 [00:00<00:03,  4.13it/s] 13%|█▎        | 2/15 [00:00<00:03,  3.78it/s] 20%|██        | 3/15 [00:00<00:03,  3.62it/s] 33%|███▎      | 5/15 [00:01<00:01,  5.74it/s] 40%|████      | 6/15 [00:01<00:01,  4.97it/s] 47%|████▋     | 7/15 [00:01<00:01,  4.65it/s] 53%|█████▎    | 8/15 [00:01<00:01,  4.42it/s] 60%|██████    | 9/15 [00:02<00:01,  4.30it/s] 67%|██████▋   | 10/15 [00:02<00:01,  4.18it/s] 73%|███████▎  | 11/15 [00:02<00:00,  4.12it/s] 80%|████████  | 12/15 [00:02<00:00,  3.97it/s] 87%|████████▋ | 13/15 [00:03<00:00,  3.68it/s] 93%|█████████▎| 14/15 [00:03<00:00,  3.71it/s]100%|██████████| 15/15 [00:03<00:00,  3.55it/s]100%|██████████| 15/15 [00:03<00:00,  4.06it/s]
0it [00:00, ?it/s]8it [00:00, 76.93it/s]17it [00:00, 92.89it/s]
Epoch 1 train loss is 1.350, click auc is 0.519 and like auc is 0.520
Epoch 1 val loss is 1.247, click auc is 0.584 and like auc is 0.671
Epoch 2 train loss is 0.727, click auc is 0.599 and like auc is 0.676
Epoch 2 val loss is 0.689, click auc is 0.614 and like auc is 0.775
Epoch 3 train loss is 0.681, click auc is 0.629 and like auc is 0.809
Epoch 3 val loss is 0.674, click auc is 0.635 and like auc is 0.831
Epoch 4 train loss is 0.665, click auc is 0.650 and like auc is 0.851
Epoch 4 val loss is 0.664, click auc is 0.650 and like auc is 0.856
Epoch 5 train loss is 0.654, click auc is 0.668 and like auc is 0.875
Epoch 5 val loss is 0.655, click auc is 0.664 and like auc is 0.872
Epoch 6 train loss is 0.645, click auc is 0.682 and like auc is 0.889
Epoch 6 val loss is 0.650, click auc is 0.674 and like auc is 0.879
Epoch 7 train loss is 0.637, click auc is 0.694 and like auc is 0.899
Epoch 7 val loss is 0.644, click auc is 0.682 and like auc is 0.888
Epoch 8 train loss is 0.630, click auc is 0.704 and like auc is 0.907
Epoch 8 val loss is 0.641, click auc is 0.688 and like auc is 0.893
Epoch 9 train loss is 0.624, click auc is 0.712 and like auc is 0.912
Epoch 9 val loss is 0.637, click auc is 0.694 and like auc is 0.896
Epoch 10 train loss is 0.617, click auc is 0.720 and like auc is 0.918
Epoch 10 val loss is 0.634, click auc is 0.699 and like auc is 0.900
Epoch 11 train loss is 0.613, click auc is 0.727 and like auc is 0.922
Epoch 11 val loss is 0.635, click auc is 0.701 and like auc is 0.902
Epoch 12 train loss is 0.608, click auc is 0.732 and like auc is 0.926
Epoch 12 val loss is 0.629, click auc is 0.706 and like auc is 0.905
Epoch 13 train loss is 0.603, click auc is 0.738 and like auc is 0.929
Epoch 13 val loss is 0.628, click auc is 0.709 and like auc is 0.906
Epoch 14 train loss is 0.599, click auc is 0.744 and like auc is 0.931
Epoch 14 val loss is 0.626, click auc is 0.712 and like auc is 0.908
Epoch 15 train loss is 0.595, click auc is 0.749 and like auc is 0.934
Epoch 15 val loss is 0.625, click auc is 0.715 and like auc is 0.909
Epoch 16 train loss is 0.591, click auc is 0.754 and like auc is 0.936
Epoch 16 val loss is 0.623, click auc is 0.717 and like auc is 0.910
Epoch 17 train loss is 0.587, click auc is 0.758 and like auc is 0.938
Epoch 17 val loss is 0.622, click auc is 0.719 and like auc is 0.912
Epoch 18 train loss is 0.584, click auc is 0.762 and like auc is 0.940
Epoch 18 val loss is 0.622, click auc is 0.721 and like auc is 0.913
Epoch 19 train loss is 0.580, click auc is 0.767 and like auc is 0.942
Epoch 19 val loss is 0.620, click auc is 0.722 and like auc is 0.914
Epoch 20 train loss is 0.577, click auc is 0.771 and like auc is 0.943
Epoch 20 val loss is 0.619, click auc is 0.724 and like auc is 0.915
Epoch 21 train loss is 0.573, click auc is 0.775 and like auc is 0.944
Epoch 21 val loss is 0.620, click auc is 0.725 and like auc is 0.915
Epoch 22 train loss is 0.571, click auc is 0.778 and like auc is 0.945
Epoch 22 val loss is 0.619, click auc is 0.726 and like auc is 0.915
Epoch 23 train loss is 0.567, click auc is 0.782 and like auc is 0.947
Epoch 23 val loss is 0.619, click auc is 0.728 and like auc is 0.917
Epoch 24 train loss is 0.563, click auc is 0.785 and like auc is 0.948
Epoch 24 val loss is 0.618, click auc is 0.729 and like auc is 0.917
Epoch 25 train loss is 0.560, click auc is 0.789 and like auc is 0.949
Epoch 25 val loss is 0.619, click auc is 0.729 and like auc is 0.917
Epoch 26 train loss is 0.557, click auc is 0.792 and like auc is 0.950
Epoch 26 val loss is 0.619, click auc is 0.730 and like auc is 0.917
Epoch 27 train loss is 0.553, click auc is 0.795 and like auc is 0.951
Epoch 27 val loss is 0.619, click auc is 0.731 and like auc is 0.918
Epoch 28 train loss is 0.551, click auc is 0.798 and like auc is 0.952
Epoch 28 val loss is 0.619, click auc is 0.732 and like auc is 0.918
val loss is not decrease in 5 epoch and break training
/home/suibe/dev_sjl/thesis/Multi-Scenario-Multi-Task-Learning/trainer.py:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path)
Epoch 28 test loss is 0.616, click auc is 0.731 and like auc is 0.912
